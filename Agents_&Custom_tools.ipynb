{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uZR3iGJJtdDE",
      "metadata": {
        "id": "uZR3iGJJtdDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e41d944-ded0-4129-e303-abf2cdba7362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.4/648.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain==0.0.150 openai\n",
        "!pip -q install duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wPdWz1IdxyBR",
      "metadata": {
        "id": "wPdWz1IdxyBR"
      },
      "source": [
        "Setting up some keys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k_oRniCLjpN",
        "outputId": "c74b943c-5750-4186-915f-179154758143"
      },
      "id": "0k_oRniCLjpN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.150\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1571b632",
      "metadata": {
        "id": "1571b632"
      },
      "source": [
        "\n",
        "# Custom Tools & Agents 🤖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02c4fa2",
      "metadata": {
        "id": "c02c4fa2"
      },
      "outputs": [],
      "source": [
        "#@title Keys\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bfcbb6",
      "metadata": {
        "id": "73bfcbb6"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the turbo LLM\n",
        "turbo_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name='gpt-3.5-turbo'\n",
        ")"
      ],
      "metadata": {
        "id": "Lald4gCltB4V"
      },
      "id": "Lald4gCltB4V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Tool"
      ],
      "metadata": {
        "id": "7DKXFGHhxNcK"
      },
      "id": "7DKXFGHhxNcK"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchTool\n",
        "from langchain.agents import Tool\n",
        "from langchain.tools import BaseTool\n",
        "\n",
        "calculator = DuckDuckGoSearchTool()\n",
        "# defining a single tool\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"calculator\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions related to calculations \"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "kOVncXZtxT_0"
      },
      "id": "kOVncXZtxT_0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom tools"
      ],
      "metadata": {
        "id": "LkEwDPN3uPvD"
      },
      "id": "LkEwDPN3uPvD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random number"
      ],
      "metadata": {
        "id": "yBLba0mTxnkM"
      },
      "id": "yBLba0mTxnkM"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_num(input=\"\"):\n",
        "    return random.randint(0,5)"
      ],
      "metadata": {
        "id": "OvPAX5Byxp-7"
      },
      "id": "OvPAX5Byxp-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_num()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ryltDax7nD",
        "outputId": "887889f7-7264-4f20-a51a-e39c6d83a7dc"
      },
      "id": "c2ryltDax7nD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tool = Tool(\n",
        "    name='Random number',\n",
        "    func= random_num,\n",
        "    description=\"Useful for when you need to get a random number. input should be 'random'\"\n",
        ")"
      ],
      "metadata": {
        "id": "fQVQNtkDyHDV"
      },
      "id": "fQVQNtkDyHDV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6e1f31b4",
      "metadata": {
        "id": "6e1f31b4"
      },
      "source": [
        "## Creating an agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "tools = [calculator, random_tool]\n",
        "\n",
        "# conversational agent memory\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key='chat_history',\n",
        "    k=3,\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "\n",
        "# create our agent\n",
        "conversational_agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=turbo_llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method='generate',\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "cskGNptztxaf"
      },
      "id": "cskGNptztxaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversational_agent(\"What is (1+9)/2 ?\")"
      ],
      "metadata": {
        "id": "uB2qtbC6rVnh"
      },
      "id": "uB2qtbC6rVnh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversational_agent(\"Can you give me a random number?\")"
      ],
      "metadata": {
        "id": "7skNxOP1q5vw"
      },
      "id": "7skNxOP1q5vw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# system prompt\n",
        "conversational_agent.agent.llm_chain.prompt.messages[0].prompt.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "q6VHBocdq6BK",
        "outputId": "2432683d-2588-41d0-b148-84e3fcb58966"
      },
      "id": "q6VHBocdq6BK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assistant is a large language model trained by OpenAI.\n",
        "\n",
        "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
        "\n",
        "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist."
      ],
      "metadata": {
        "id": "VZ22ia6VCjf-"
      },
      "id": "VZ22ia6VCjf-"
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_prompt = '''Assistant is a large language model trained by OpenAI.\n",
        "\n",
        "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
        "\n",
        "Assistant doesn't know anything about random numbers or anything related to calculations and should use a tool for questions about these topics.\n",
        "\n",
        "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
        "\n",
        "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.'''"
      ],
      "metadata": {
        "id": "xuCF3bzDsLUv"
      },
      "id": "xuCF3bzDsLUv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages[0].prompt.template = fixed_prompt"
      ],
      "metadata": {
        "id": "zZBP6l2EsIT5"
      },
      "id": "zZBP6l2EsIT5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Tool Class - lets make a useful tool\n"
      ],
      "metadata": {
        "id": "RLf1c3ejtyC4"
      },
      "id": "RLf1c3ejtyC4"
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def stripped_webpage(webpage):\n",
        "    response = requests.get(webpage)\n",
        "    html_content = response.text\n",
        "\n",
        "    def strip_html_tags(html_content):\n",
        "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "        stripped_text = soup.get_text()\n",
        "        return stripped_text\n",
        "\n",
        "    stripped_content = strip_html_tags(html_content)\n",
        "\n",
        "    if len(stripped_content) > 4000:\n",
        "        stripped_content = stripped_content[:4000]\n",
        "    return stripped_content\n"
      ],
      "metadata": {
        "id": "mkgJmIWhpLIU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "mkgJmIWhpLIU"
    },
    {
      "cell_type": "code",
      "source": [
        "stripped_webpage('https://www.google.com')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "c8c9ZSgUGCgS",
        "outputId": "34aba7d1-e352-4928-d34e-1d1ee29167b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in\\xa0Advanced searchMeet social innovators striving to change the world with help from Google.orgAdvertisingBusiness SolutionsAbout Google© 2023 - Privacy - Terms   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "id": "c8c9ZSgUGCgS"
    },
    {
      "cell_type": "code",
      "source": [
        "# webpage_tool = Tool(\n",
        "#     name='Get Webpage',\n",
        "#     func= stripped_webpage,\n",
        "#     description=\"Useful for when you need to get the http from a specific webpage\"\n",
        "# )"
      ],
      "metadata": {
        "id": "0uJBO5rkIroU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0uJBO5rkIroU"
    },
    {
      "cell_type": "code",
      "source": [
        "class WebPageTool(BaseTool):\n",
        "    name = \"Get Webpage\"\n",
        "    description = \"Useful for when you need to get the content from a specific webpage\"\n",
        "\n",
        "    def _run(self, webpage: str):\n",
        "        response = requests.get(webpage)\n",
        "        html_content = response.text\n",
        "\n",
        "        def strip_html_tags(html_content):\n",
        "            soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "            stripped_text = soup.get_text()\n",
        "            return stripped_text\n",
        "\n",
        "        stripped_content = strip_html_tags(html_content)\n",
        "        if len(stripped_content) > 4000:\n",
        "            stripped_content = stripped_content[:4000]\n",
        "        return stripped_content\n",
        "\n",
        "    def _arun(self, webpage: str):\n",
        "        raise NotImplementedError(\"This tool does not support async\")\n",
        "\n",
        "page_getter = WebPageTool()"
      ],
      "metadata": {
        "id": "CaYulMSjuC5B"
      },
      "id": "CaYulMSjuC5B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6325f758",
      "metadata": {
        "id": "6325f758"
      },
      "source": [
        "## Init the Agent again"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_prompt = '''Assistant is a large language model trained by OpenAI.\n",
        "\n",
        "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
        "\n",
        "Assistant doesn't know anything about random numbers or anything related to the calculations and should use a tool for questions about these topics.\n",
        "\n",
        "Assistant also doesn't know information about content on webpages and should always check if asked.\n",
        "\n",
        "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.'''"
      ],
      "metadata": {
        "id": "gvlHC6vpzyNs"
      },
      "execution_count": null,
      "outputs": [],
      "id": "gvlHC6vpzyNs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6579cef0",
      "metadata": {
        "id": "6579cef0"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
        "tools = [page_getter, random_tool]\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent='chat-conversational-react-description',\n",
        "    tools=tools,\n",
        "    llm=turbo_llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages[0].prompt.template = fixed_prompt"
      ],
      "metadata": {
        "id": "DAjZHjOqzyNt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "DAjZHjOqzyNt"
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent.agent.llm_chain.prompt.messages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ARQHOR41u5g",
        "outputId": "4e8b6ea2-fc5d-4369-e189-367f873a8462"
      },
      "id": "4ARQHOR41u5g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template=\"Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant doesn't know anything about random numbers or anything related to the meaning of life and should use a tool for questions about these topics.\\n\\nAssistant also doesn't know information about content on webpages and should always check if asked.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\", template_format='f-string', validate_template=True), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent.run(\"What are the titles of the top stories on https://www.cbe.org.eg?\")"
      ],
      "metadata": {
        "id": "4SSjIjI30rtZ"
      },
      "id": "4SSjIjI30rtZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hej1rBdW2U72"
      },
      "id": "hej1rBdW2U72",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "langchain"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "578e1e8dce4dc6c542f1ea2d66a2d9db6ef592936dcc314004bdae386f827d38"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}